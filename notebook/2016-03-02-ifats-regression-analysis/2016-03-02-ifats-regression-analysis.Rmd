---
layout: default
tags: [ regression, reproducible-research ]
title: Repeating Ifat's Regression Analysis with 5 More Genes
---

```{r echo=FALSE}
options(width=106)
```

## Goal

Reproduce and extend Ifat's previous regression analysis (documented [here][regression-slide], see also speaker notes for that slide) using the following sets of genes:

* "8 genes that looked promising on the 2X2 table fisher exact test"
* "all 13 genes from slide 3"

```{r echo=TRUE}
genes13 <- c("PEG3", "INPP5F", "SNRPN", "PWAR6", "ZDBF2", "MEG3", "ZNF331",
           "GRB10", "PEG10", "SNHG14", "NAP1L5", "KCNQ1OT1", "MEST" )
```

The question is the **sensitivity** of the results of regression analysis to the gene set $$G$$.

## Ifat's script

To aid reproducibility, I turned Ifat's code into two functions (`transform.data` and `fit.lm`) stored in the source file below.
```{r}
source("2016-03-02-ifats-regression-analysis.R")
```

### Input files

Here I denote the test statitic for monoallelic expression as $$S_{ig}$$ for individual $$i$$ and gene $$g$$.  The corresponding matrix is $$S = [ S_{ig}  ]$$.  Based on Ifat's code, a data transformation (explained below) on $$S$$ gives rise to $$\mathrm{LOI\_R}$$.  $$\mathrm{LOI\_R}$$ plays the role of the response variable in the regression analysis.  The explanatory variables are arranged in the design matrix $$X = [ x_{ij} ]$$ for all individuals $$i$$ and variable type $$j$$.

|     content                                |       file                         |
|:-------------------------------------------|:-----------------------------------|
|   $$S$$                                      |   `pop_skew_3June15.txt`           |
| subject info, part of $$X$$                  |   `samples.csv`                    |
|  ???, part of $$X$$    |`DLPFC.ensembl.KNOWN_AND_SVA.ADJUST.SAMPLE_COVARIATES.tsv`|         


### Mathematical formulation

The `R` command for linear regression in Ifat's code is
```{r eval=FALSE}
glm(LOI_R ~ (`Age.of.Death` > age.thrs) + Institution + ... + `Ancestry.EV.5`, 
    data=FULL)
```
which corresponds to the normal linear model
$$
\begin{equation} \mathrm{LOI\_R} = X \beta + \epsilon \end{equation}
$$
where $$\epsilon$$ is a vector of independent normal variables each with mean 0 and variance $$\sigma^2$$.

How is $$S$$ transformed into $$\mathrm{LOI\_R}$$?
Let's inspect Ifat's code, in which the `S2` matrix variable corresponds to the matrix $$S$$ of response variables, as above.
```{r eval=FALSE}
# rank individuals for each gene
for (g in seq_along(genes)){
  gene=genes[g]
  gene_data<-as.numeric(round(S2[,gene],3))
  gene_rank<-rank(gene_data,ties.method = "min",na.last = "keep") # do the ranking
  R[,gene]<-gene_rank
  #...
  rank_max<-max(R[,gene], na.rm = TRUE)
}
#...
# average rank over genes for each individual
for (s in 1:579){
#...
  PR[s,gene]<-as.numeric(round(R[s,gene]/rank_max*100,0))
  #...
  LOI_R[s,1]<-as.numeric(sprintf("%.0f",mean(PR[s,],na.rm = TRUE)))
}
```

Let $$m$$ be the number of individuals and $$G$$ the set of selected genes.  Then
the above code chunk means the definition $$\mathrm{LOI\_R}=100 \times m^{-1} \times (\bar{R}_1,...,\bar{R}_m)$$, where

$$
\begin{eqnarray}
\bar{R}_i &=&  \mid G \mid ^{-1} \sum_{g\in{G}} R_{ig}
\end{eqnarray}
$$

### Consequence on confidence intervals

Let  $$\beta_j$$ denote a regression parameter of interest for some explanatory variable $$x_j$$, say for the age of death. Let $$\hat{\beta}_j$$ be the least squares (i.e. maximum likelihood) *estimate* of $$\beta_j$$.  We want to test the null hypothesis that $$\beta_j=0$$, which we interpret as no influence of age on allelic exclusion. To test that hypothesis at significance level $$\alpha$$, we need to calculate $$\mathrm{CI}_{1-\alpha}$$, the $$1-\alpha$$ confidence interval for $$\beta_j$$ and see if $$0\in\mathrm{CI}_{1-\alpha}$$, in which case the null hypothesis is supported. The [calculation][CI-wiki] of $$\mathrm{CI}_{1-\alpha}$$ follows from normal distribution theory and [weighted linear least squares][weighted], which together imply that the statistic
$$
\begin{equation}
T = \frac{\hat{\beta}_j - \beta_j}{\sqrt{w^{-1}S^2(X^\top X)^{-1}_{jj}}}
\end{equation}
$$
has Student's t-distribution with $$m - p$$ degrees of freedom, where $$m$$ is the number of individuals and $$p$$ is the number of parameters (one more than the number of explanatory variables).  The denominator is the *standard error* for $$\hat{\beta}_j$$ and includes the following terms:

* $$w$$, a uniform weight on each of the $$m$$ observations
* $$S^2$$, the residual sum of squares divided by $$m-p$$, which is an unbiased estimator for $$\sigma^2$$
* the inverse covariance matrix based on the design matrix $$X$$

Weight $$w$$ is central here.  Since for each individual $$i$$ the average rank $$\bar{R}_i$$ is the average of $$ \mid G \mid $$ number of genes, all $$m$$ rank observations receive weight $$w= \mid G \mid $$.

With observed $$S^2=s^2$$ the confidence interval is $$\mathrm{CI}_{1-\alpha} = \hat{\beta}_j \pm  t(\alpha/2) \sqrt{ \mid G \mid ^{-1}s^2(X^\top X)^{-1}_{jj}}$$, where $$t(q)$$ is the $$q$$ quantile of the t-distribution with $$m - p$$ degrees of freedom.  Thus, averaging across all genes in the selected set $$G$$ shrinks the standard error by a factor of $$ \mid G \mid ^{-1/2}$$ and consequently shrinks the $$1-\alpha$$ confidence interval by the same factor, which is about 0.35 for the 8 gene set and 0.28 for the 13 gene set.  The shrinkage in turn leads to more significant p-values.

But the `R` code chunk for linear regression (above) shows that the default $$w=1$$ was used mistakenly instead of $$w= \mid G \mid $$ and thus the shrinkage effect of averaging $$ \mid G \mid $$ genes was ignored.  Consequently, the mistake has lead to a $$\sqrt{ \mid G \mid }$$-fold **overestimation** of the standard error and of the $$1-\alpha$$ confidence interval, and ultimately to a **less significant** p-value.

## Reanalysis

The design matrix $$X$$ has actually two versions: one where age is a continuous variable and another one where age is a binary variable indicating whether an individual deceased before or after a threshold (set to 70 years).  The following commands carry out the regression for both versions of $$X$$ and
both gene sets (the set of 8 and that of 13 genes):

```{r cache=TRUE}
m8.thrs <- fit.lm(transform.data(genes13, genes13[1:8]), do.thrs=TRUE, age.thrs=70)
m13.thrs <- fit.lm(transform.data(genes13, genes13), do.thrs=TRUE, age.thrs=70)
m8 <- fit.lm(transform.data(genes13, genes13[1:8]), do.thrs=FALSE)
m13 <- fit.lm(transform.data(genes13, genes13), do.thrs=FALSE)
```

## Results

The detailed, quantitative, results are below.
Qualitatively, they show that using 13 instead of only 8 genes...

1. has little impact on parameter estimates,
2. slightly decreases most standard errors,
3. but slightly weakens significance (increases p-values).

The last two points together suggest that age and other explanatory variables tend to impact the originally selected 8 genes more strongly than the remaining 5 genes.

### With age threshold (70 years)

#### 8 out of 13 genes

```{r echo=FALSE}
summary(m8.thrs)
```

#### All 13 genes

```{r echo=FALSE}
summary(m13.thrs)
```

### Without age threshold

#### 8 out of 13 genes

```{r echo=FALSE}
summary(m8)
```

#### All 13 genes

```{r echo=FALSE}
summary(m13)
```

[regression-slide]: https://docs.google.com/presentation/d/1YvpA1AJ-zzir1Iw0F25tO9x8gkSAzqaO4fjB7K3zBhE/edit#slide=id.p9
[CI-wiki]: https://en.wikipedia.org/wiki/Student%27s_t-distribution#Confidence_intervals
[weighted]: https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)#Weighted_linear_least_squares
